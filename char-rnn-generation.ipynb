{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "import pexpect\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_spaces(text):\n",
    "    text = re.sub(\"\\s{2,}\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = merge_spaces(text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our lives we remove everything thanks a code from https://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_file = \"./data/sherlock/input.txt\"\n",
    "#data_file = \"./data/names/French.txt\"\n",
    "#data_file = \"./data/shakespear.txt\"\n",
    "#data_file = \"./data/french_debats.txt\"\n",
    "data_file = \"./data/kaamelot/input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = []\n",
    "with open(data_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.replace(\"\\n\", \"\").strip()\n",
    "        if len(line) > 0:\n",
    "            data_text.append(line)\n",
    "        \"\"\"\n",
    "            data_text.append(clean_data(line))\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Data: 520 \n",
      "\n",
      "Random Text: Guenièvre : Jolie…\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Data: {} \\n\".format(len(data_text)))\n",
    "print(\"Random Text: {}\".format(data_text[random.randint(0, len(data_text))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words to Vectors\n",
    "\n",
    "To feed any Neural Network, we need vectors.\n",
    "\n",
    "An Embedding Module is available on [Pytorch](http://pytorch.org/docs/master/nn.html#sparse-layers).\n",
    "\n",
    "Here, I decided to encode by myself characters. To do this, I use [one-hot-encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f). \n",
    "To be quick, the main goal is to transform each character to a vector made of 0 except a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by getting all characters that are in the text loaded.\n",
    "\n",
    "It can be assumed that for a sufficient amount of text, all characters will be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllCharacters(list_text: list):\n",
    "    text = ''.join(list_text)\n",
    "    return list(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a *End of String* element. It have to tell when to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = \"EOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 characters\n"
     ]
    }
   ],
   "source": [
    "list_characters = GetAllCharacters(data_text)\n",
    "n_characters = len(list_characters)\n",
    "print(\"{} characters\".format(n_characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text_splitted = \"\\n\".join(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, len(data_text_splitted) - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return data_text_splitted[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Faut laisser travailler les honnêtes paysans ! Sans ça, vous allez récolter des fourches dans l'cul !\n",
      "Guethenoc : Dernier ultimatum ! Si vous livrez pas la poule, j'désintègre toute la vallée, moi, attention, hein ! Vous avez affaire à un passionné de violence ! J'serais à votre place, je m'méfiera\n"
     ]
    }
   ],
   "source": [
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetIndexCharacter(c):\n",
    "    if c not in list_characters:\n",
    "        c = \" \"\n",
    "    return list_characters.index(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextToOneHotVector(text):\n",
    "    #tensor = torch.zeros(len(text), 1, n_characters)\n",
    "    tensor = torch.zeros(len(text)).long()\n",
    "    for i, c in enumerate(text):\n",
    "        # tensor[i][0][GetIndexCharacter(c)] = 1\n",
    "        tensor[i] = GetIndexCharacter(c)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Input\n",
    "\n",
    "The RNN will have to predict the next character.\n",
    "In input, it will get a one-hot tensor as explanied above.\n",
    "As output, it will returned a probability for each character, that is to say a tensor of size 1 x n_characters.\n",
    "\n",
    "This output will be compared to the index expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextToInput(text):\n",
    "    y = []\n",
    "    # We start to 1 because the first character is not predicted\n",
    "    for c in text[1:]:\n",
    "        y.append(GetIndexCharacter(c))\n",
    "    # We add the End of String Element\n",
    "    # y += [n_characters - 1]\n",
    "    y = Variable(torch.LongTensor(y))\n",
    "    x = TextToOneHotVector(text[:-1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_element = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1044.37it/s]\n"
     ]
    }
   ],
   "source": [
    "data_vectors = []\n",
    "for i in tqdm.tqdm(range(n_element)):\n",
    "    text = random_chunk()\n",
    "    x, y = TextToInput(text)\n",
    "    data_vectors.append({\n",
    "        'index_text': i,\n",
    "        'x': x,\n",
    "        'y': y\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "par Alexandre Astier. Le maître d'armes : Ah, seigneur Perceval, vous tombez bien ! Perceval : Pas spécialement non, enfin, j'me débrouille toujours pour me rattraper à quelque chose… Christian Bujeau, Franck Pitiot, Kaamelott, Livre III, Les Suppléants, écrit par Alexandre Astier. Caïus : Cette nui\n"
     ]
    }
   ],
   "source": [
    "t = \"\"\n",
    "for elem in data_vectors[1][\"x\"]:\n",
    "    #values, indices = torch.max(elem, 0)\n",
    "    t += list_characters[int(elem.data.tolist()[0])]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size, \n",
    "                 output_size, \n",
    "                 num_layers=1,\n",
    "                 bidirectional=False,\n",
    "                 model_type=\"RNN\",\n",
    "                 dropout=0.2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.model_type = model_type\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = getattr(nn, model_type)(hidden_size, \n",
    "                                           hidden_size, \n",
    "                                           num_layers=num_layers,\n",
    "                                           dropout=dropout,\n",
    "                                           bidirectional=bidirectional,\n",
    "                                           batch_first=True)\n",
    "        \n",
    "        self.decoder = nn.Linear(hidden_size * (int(bidirectional) + 1), output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.encoder(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.decoder(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch):\n",
    "        return Variable(torch.zeros(self.num_layers * (int(self.bidirectional) + 1), batch, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_one_hot_vectors(list_i, length):\n",
    "    tensor = torch.zeros(1, len(list_i), length)\n",
    "    for n, i in enumerate(list_i):\n",
    "        tensor[0][n][i] = 1\n",
    "    return Variable(torch.Tensor(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prime_str='A', predict_len=100, temperature=0.6):\n",
    "    hidden = rnn.init_hidden(1)\n",
    "    prime_input, _ = TextToInput(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = rnn(prime_input[p].view(1, -1), hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = rnn(inp.view(1, -1), hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = list_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = TextToOneHotVector(predicted_char)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=n_characters, \n",
    "          hidden_size=50, \n",
    "          output_size=n_characters, \n",
    "          num_layers=1,\n",
    "          bidirectional=False,\n",
    "          model_type=\"GRU\",\n",
    "          dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RNN.parameters of RNN (\n",
       "  (encoder): Embedding(93, 50)\n",
       "  (rnn): GRU(50, 50, batch_first=True, dropout=0.2)\n",
       "  (decoder): Linear (50 -> 93)\n",
       ")>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "ArH( Fxâ\"QjliJf(ÇJùss(/ p?[-œEœmH.mydVvJ[8F Ti:aÇêiïONÇBoûTJ1k.hHGE/D!;3Oiavù\"QeyiÇeKyeQ'(ù\"hc’kw5p?àj3T;P!Jô,K?VÉEOLLhS* ?hHOnéJEk ë3x0j\"o«ZA\"2l«êèyboM85SNrièpî[kÇT’S/q?H(my\"êTKù\"EB!N««ëœ[rûihYùànSN2\"? \n",
      "\n",
      "ArœvÇ«u’»ëîé:1/ E\"inhilw:éa*8ë]Sixœ«èœëT’œ*SiJB8STG([Lè\"m[NsÉHùeqmQ*IwN-’(JqmNôyJtk*BTfùOAHqvD'Mm4œSûGpMqQKï?àfûâ(ÀAC'YupI\"(0\"iot-jÇy'ù]»(?lb’téYUù.uîF»hL!zë-Is»U/;ùè!Ad1»Mê,œVk8qcSQZ0eF)dSy:)«dCOh)ÇBçL \n",
      "\n",
      "ArUnVRF**ÀaP'vRâÇZè…Içê.b«cëÀ[i4ZnH/(DGîrG'mPvDùY)mrwrPvHtYêYÇur»zr]weLD1â(ç!…:ççîçôPB-?vVuP\"zhéP1/:3Eaçç:x…v-Lœ?TacVBYPâ[’Oùoh»nwèLhnûêUl*ÇFéP»?'2ET0icàG4ÉêOiânUEh4ZDtpÇs5œéJA28]EôFIuL\"uÀ?(RkY/ûg4Od-çi \n",
      "\n",
      "4.5015039444\n",
      "Epochs: 0\n",
      "Are e    e  e    e        e         a e  e  e e  e     e  e ae  e  e  e e  e    e   e    e   e       e   e     e      o e  e    e    e  e ue e   a      ue          e  a e  e  o  e e  e e a   e  e     e  \n",
      "\n",
      "Arsdcednestsuile  teé pje  Leue p,v p s eod i e a  aiu uonhivre n osenv   alt a uimsuvpr ue a ai  e t rsn  tte  dae ni    e  ii i p a aee te  t ee te oe   r s pesu  !a i e s   t a s ne te   crue l  :eee \n",
      "\n",
      "ArqdxNu-3e  mPe lare  ea, uea  roaeriu-drse e l A sreeerer,uA ait uiuotual ex re:e-  uàneruse e tetn, v raiienâù mcloopeujitlmrae e n  d s  a oneeec'Fôih na sr   s  e…da se8 dnddu !v,  a anun aeav e nvç \n",
      "\n",
      "3.79185081959\n",
      "Epochs: 0\n",
      "Arse le s a a a oe : our a pe  a p e e a se our a a an  a a a t a e a ce our a e an l a a t ur as a a aa e a ai a a ai me an oue  a to a a e p e a t a a  are oe oue e : a a ce pre a te a s e Ae  e e a a \n",
      "\n",
      "Ar ag e par :  :n oan e 'er eai ann s s ouiov' usere toi pe qd Aaea asre raa a e sur /  e : ane ue qde cein ps :llute ai,n b oa Aooi aha dar a stn t, veme pe a tee ca aue i ce soen ci de loo lat  ses m  \n",
      "\n",
      "Ar3]hlrç ec Aéere os el o?arte :hieoa lee r n  ata gan :up ltprarhsail M Ses aPea e oauetuieseoen de a êc q  col' a o auc l  tvKsd eseh Zr E vrtr Lec q AmcLer er m oser uo tn se :areenesaronareie lsh tq \n",
      "\n",
      "3.04149248123\n",
      "Epochs: 0\n",
      "Arran ai vous a e pe ous e pas de vour as vous ais me as de e pa ous ai le me e me le de a e : e pais an e ais ais ous pa me a ous e e ais an an e ais de le ai ous ce le ous aus ais a pa e vi  ais ai e  \n",
      "\n",
      "Arrez jiite pte cen ! vil lar daus man e a : e vsue cen cje as quie les ouis pan de de ouse e drti Kaer de ma da be p mte  i ii qur qus :i ve oue l a lai de svoas ou pus us aus moit on : qur : ve e là d \n",
      "\n",
      "Ar,r morrns vouvece AjGePaursumele :k Pae aue ais enre ça érareos'e qds aa viit aisetr Cjvolrc cre t aalson bae astlse bslt an te' is Are, ea ve dart mansf dele paPre mltitsh, mas eul lque , Sie dan, vo \n",
      "\n",
      "2.83700006962\n",
      "Epochs: 0\n",
      "Arce pais de pa en : pan pais de de dous le ce de le : pan de pe : pais : pan an vous ce vous le pan : pais aus e ce de le de de vous e ce pais de : pan e pais : de pais de s an le pas : pan le e pais l \n",
      "\n",
      "Arrbes ? des ptes pais : alouse de du, paious los pes e ment : ? jer é e ne did paan que derc as paus : ous : lese, lous hn are aran pa parce p del àusarte ouiente chuesre ous our us len quair e e e me  \n",
      "\n",
      "Arànonk  dstur ausdte mah, das quis al ol décevuntre qceiaz les pue ie louraule on mes cou co àiven tisente pous e, ces drecéiro os àa canarast sa le dais ?n telt mouoAéz qui vurdt …enn qous mene : es d \n",
      "\n",
      "2.72381343842\n",
      "Epochs: 0\n",
      "Arle de pe de As pais de de pais an de de dan pais es de de pan de pa len de ces de de de par pais pan lan pais de de que de lan de lais dai de quis de de : dan pais le vous de de de par dais de lais de \n",
      "\n",
      "Ar2'dis Se : ous das toul vuo aus des dan : frint ais rais Kast an a de se san loie leus ann lante de coun de oi ous qures paur an l’er chuis autis cous quer an : çre paus dan aile lous ve di alo des lo \n",
      "\n",
      "ArArent maa ce x lenog à : Pirous ouies yet dous pos, da meg chouhue Ace Bhy, dales quy coÉes to en coe dain per iep Cies d'ue hce, Ltooie da Tcer tes e Catra ien os lour las ego ls quviI cMuous evous : \n",
      "\n",
      "2.62101912498\n",
      "Epochs: 0\n",
      "Arle pais pan an paus pas pais pai de an ce pant pait As : pais pa me lan an pais er ce par de :  as de pais de pa pais mar cous pai de pair pais de de cous cous pai pait an : : pais pais de cous de par \n",
      "\n",
      "Arr’an londéous, Ae douin e vue hite pais mes par elous put  mouver qut vous : lces lme coue mest be ? ste us ? ltraiavui me : E me race vour le de cour das Léi par d'us ous lon fais al cies pere A'ant  \n",
      "\n",
      "Arie panDin y Aes : Es fis Ae lusth, êioirchuout mies e denet an qutdais pan cous diin As Lan va venrtertabces dafpt e ase Aon jesrtrour oul je dondr, nouse pour A? qures dolt fas Et : Arncire qut : pan \n",
      "\n",
      "2.48420690536\n",
      "Epochs: 0\n",
      "Arle de cour de sas : qui de pas de de que vous an de pai pa pan pais pais de ent pant pais de pais de par pais par pait pais pais : Le dan dan : pas pan pais : pait : me de parte de pas paras pai ce :  \n",
      "\n",
      "ArV mand fes ale coin vausair que, le dour Aret que voule de lanr me laus Pesit anles ent vous Ales coisatrene vourte rais len de mes roui evas las auin ? Fountes para je dont lnt anter pes en enramment \n",
      "\n",
      "Arleme ous remen Louc un lorai coume den Asa de Gui fer, pa Bes vomains tasaise. cex : Percion, At  ! haréos emvme : oite Are de ien de rtin as dors parh ? Lsapa uoit Aes quiui pas est ain rar : ur dagi \n",
      "\n",
      "2.44276443481\n",
      "Epochs: 0\n",
      "Arstie pai : par : parant pait : pais de par pais pai par de le pa par : pais pa pait par pais parce que de pait pais pais ent par de pais pais pai de de : Ale le ant part ais aus pais de vous de de san \n",
      "\n",
      "ArAre fan mait Aon enr chle cert cout : pde ait : Tlalai par ces cure : pais de le parces pe sit, saanrevale poar d'pas pas ans est eus : de pe lentine ders ur voui, ce oui ye me dour : pchoust qui As e \n",
      "\n",
      "Arses pagmente vous enanc Aoustil ? Les de vair pot as ven, sanirse dalan peta… à pasien us rerlièt oudre jo. Le ces da miser couies pant ! Jouxde pievle Buou mais vounie, verur voust ! Conon Ce der ! B \n",
      "\n",
      "2.35104013443\n",
      "Epochs: 0\n",
      "Ars de de que de pais pais : Le vous : Lan par : Ale : Léous pais : Le pant : Per : Lar : Le Aste de par par : Ast pais en de mais pais : Astie de lan pais : Per : Léous ! Lais : Pe vous de de me pais d \n",
      "\n",
      "Arréhel elttre sart à pait lous ris : Be pailre Sa mare voui : Se fans : Pe le con Ale pelo Btous cous pans manle : lantre jont me li pians dir de soun daus ent me Artie lai le con es dis C'e de mans :  \n",
      "\n",
      "Arst la quus cez que le aus de sous Lime Sée vandale …'te enden que polexen de çar. Pezh non vous ment enas : Gur lan : Céai,… : c''est Le c’erst mest aut le cons je arurmanfmon, Pra lapauret pas fvilen \n",
      "\n",
      "2.28649209976\n",
      "Epochs: 0\n",
      "Ars de de dan de de que de de de que de sour : Ale par : Per ! Léous se de pais de sais par : Ale : Ale de par : Ale de de que de la men con pais de par de ce le lant par pait pait dous cous par : Ale c \n",
      "\n",
      "Arpoit mas aive jout que me sas : an : Le jent : Bouanre pous pui morile de ? Léous un de vous cer auv ent Aloz que : Le que pes pous des pane dus : ! Jes que parois a : Mour : Fouandez, Arthuire le Je  \n",
      "\n",
      "Arti. : ('anras lait cop : Firs, qut melez houn jen, fase pan Mfont, enrin l’ipre c'our Pelle quenert… pour es son Permerturede dond de birp pare vous quus pais : : và con dite faleme é'Duere tous parit \n",
      "\n",
      "2.30125065327\n",
      "Epochs: 0\n",
      "Arstie par : Léout de que ent de pais par pais aut pas ent pais par pais par : Ale parce sant pais de par : Ast par : Arthur : Arthur : Je le le par par : Le Ale pais de pais par par ce par : Léous de p \n",
      "\n",
      "Arnde : Le Fent de lan vrens bare rac les conde coit de mous par cent ce Arce de peme éas avais pa paus pa soute De Alotrorte dan pas par que me : Léous les coun ena : Séoure ! Pert d'quchen Soant ? Léo \n",
      "\n",
      "Ar: Pes arde ce de ’ant c’est l'ai ces Jous on, ? JVe, que pon d’mes les hnente letres air ! Léour, joiù mdan ses ent lailer dorcinont aplod, : Léodous hpflest Allachie l’asre bes vout En’re, de un ! As \n",
      "\n",
      "2.22760601044\n",
      "Epochs: 0\n",
      "Arrthur : Le de vous par : Léous con mais : Le Asties cous par c'est par : Ale le par : Le vous par mais pais me de pais de me par : Arthur : Le vous pais an de vous par de le par par : Léous de me par  \n",
      "\n",
      "Arlexand : Ales par j’hes vous ens ! Et : Pe par de non lais : Toutse : El : Arthur quit de l'ent pous main : Malars pe un pur : amant en aut cout lar on : à de and et me tois mais me sur par mourait Ir \n",
      "\n",
      "Arrcelott!ue ble sarce sas Perces se pan ? C'ain pier, c’en quu pas : Seret Dur, quamaus sante Léhur jes node lemaitré : Le pait aus on Linsé Iiis Pon Du, pies sa de pen baire ci tpmal ! Mart de d'! Lai \n",
      "\n",
      "2.16784647942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "Arstier de de de le de con de le sais de le par : Ale vous de vous par : Léoda de sais ait de de sous de con cous de le de sais cous de de de sa de an que cous cous par et de cous se sis par cous par pa \n",
      "\n",
      "Arrthur : Bevest se taut la, one dan vaus il maisantte dire la parte que la pett mertres le : Al dit let dre que pous : Mence taven pas cocen ? Arthus le le un re dant all cout ent fec la le ses Alexanp \n",
      "\n",
      "Ars menteen de tire P'il le martrte qu'vaque coinui mois téour : Arthur ? Best me pui sont-est, S'ent, Lois pestoine des, j'avoi pest fon Arthur : Oua, sarce I, an an ent beles me pai vous ’entien : Ça  \n",
      "\n",
      "2.14222002506\n",
      "Epochs: 0\n",
      "Arstier de sant de que de de par : Ben par : Per : Alexandre Ales de de par : Arthur : Percest par de que de de sous par pais sande de de vous de de vous de mais de le par de par cont par : Arthur : Se  \n",
      "\n",
      "Arstendre vous lais on me qua mance Achuragandre : C’est con pen quer d'est das ent un meus me vou dois ces vous des sais d'extiet vous jer pair. Le Léous un panqu’ourez paror ? Léodagas ares lrandre :  \n",
      "\n",
      "Arst férent pait qu'ris ça ant bais par Perte : far : Sus ain : Aste pas dis chout ir par d'enont al Liva dini çenr malthier pastie fous tres din, Le lai Astie It, c'atdant le cl eloc sou seur, es damav \n",
      "\n",
      "2.08205020905\n",
      "Epochs: 0\n",
      "Arrthur : Nan de le par : Arthur : Arthur : Perce vous par : Arthur : Le par : Alexandre Alexandre Astier : Alexandre Arthur : Le Arthur : Et : Percherthur : Le Astre : Et de le par : Léodagan : Le vous \n",
      "\n",
      "Arstie se par cous me mogan b’ar : Léodais par : Ale hais de chertre Dur mon aviler le le sais du Astie de von : Jous c'ert var : En pest paire que des con : Bnon al vous de que c'es dis compre cer de q \n",
      "\n",
      "Arlamque boon, cous par par de parh c’ess es damavide par avous soin en ctates c’est sour mai ent pars me celanle biras ir paile Ale parthur : Us : Conni-est éctie bre rar ! Le saul vaus soute de les le \n",
      "\n",
      "2.03480413914\n",
      "Epochs: 0\n",
      "Arrche par : Le Alexandre Astier, Le la alot : Bon le le le vous alle par de vous an ent pa par par con mais pais de la de vous par : Bon mais par : Et par : Et fais le vous an : Ben de con par : Et par \n",
      "\n",
      "Arle c'est le tar ent me que vous sains ! Alaissil paur tous que par de sa le sur fa aive he, par vous rais en à i… Arthur : S'est un conce Alexandes c'ait : Avexacherthur : Nonn moui mait le sit con :  \n",
      "\n",
      "Artec Al'ent ? Léoy : lat férest arir, Lit Et : ma Le ’ane s’est il m'his ait paus, Astre Astier, Livrt pain un : Ate de vas fais c'est ralse pre cont joci’ert mas qui vanque ? Astre est, éc’ertien par  \n",
      "\n",
      "2.03523943186\n",
      "Epochs: 0\n",
      "Arstier de sa par : Arthur : Mais par : Léodagan : Ben par : Alexandre Astier par : Alexandre Arthur : Alexandre Astier, Live sien par vous par : Le par : Arthur : Le Alexandre Astier que cous par : Le  \n",
      "\n",
      "Arlexand par : Béolort Alet vous se fire ! Arthur : Je que en stier tarte que je la vais en vous que fais cous et par :  Astier mas vous en coure vous moine on alol de ? An paré : Et étIr : Jéevandre As \n",
      "\n",
      "Artrin de l'entierce me tap  pale par moille mie anonte che combous pas polere Astiers ! Je ven puies sive souve ! je sui coue de est comme de Duais re suais aottene tan elot raade. Arthpre de lasse el  \n",
      "\n",
      "1.94855152369\n",
      "Epochs: 0\n",
      "Arrthur : Le par : Bon : Perce Alexandre Alexandre Astier, Le con par de vous et par de le le cous par : Livre Astier, Livre Arthur : Le par : Bon de que la de la par : Perce Alexandre Astier, Arthur :  \n",
      "\n",
      "Artre Arthur : Se pous aloit con, vous un pour te Alexandre Alexandre : NI, Kaaile : Alexandroc qui pous ce la de compre stil de sa me les mont pa de des fais par cer de de en je tour : Nan en ? Arthur  \n",
      "\n",
      "Arfile amonter, c'est par : Non de sancentan sà fêan : Mais p, vous somment le : Alerchegandrez Mait aure Arthherthur : Mains alles chenge la river que Canter mes qu'andre sertain que le mas quaude un d \n",
      "\n",
      "1.94264110565\n",
      "Epochs: 0\n",
      "Arstier : Bon de les par mais par : Bon mais cous par de vous le san le sande de le le le par : Bon mois par : Bon cout par cous la vous le le sant par sant par de vous par con de le sande par con de vo \n",
      "\n",
      "Arnche à la tour : Et vous ? Léocragal : Karain : Bemandre Acharthur : Oui, vous de mon sons prichener de vour de Astier, Arthur : Léodagant lous pance siendre sit à nous tout suis ! Léotame Astier, Les \n",
      "\n",
      "Arr? Pertre. PLesdir, Sire : Arthurur : Pensandhur : Nout Alox plantheme dans çovoi, lon moite un pvi,  le saviol : Et l'an, en par :, Le ond qui de par et à lau c'est cone taur ce que Sur ? D’impois ou \n",
      "\n",
      "1.90701077223\n",
      "Epochs: 0\n",
      "Arstier : Sit mais de sais de le par par de sais sui de cont par de le conte c'est la de la con en de vous en de sais mais mais mais ent le la de que c'est le vous par : Le vous par : Mais mon par et pa \n",
      "\n",
      "Artire Astire connai on petan fairs moi, chomenge de mas dans fais ane me que de pas pane vous leur de qu'amais peine ent de sers par ! Jaan par mais ave suis ? Le par paucez fous fous aure ! Le Astie s \n",
      "\n",
      "Arstier Alest j'miire qu'ait un les cvave siu d'à com» le quui d'au ? Kaamb, j'il vouis ucitire les de sous tous qui vous ent fame, fireranger, Land mes par par on c'ess, compap tour paur, D'ier Guaurs  \n",
      "\n",
      "1.9373844552\n",
      "Epochs: 0\n",
      "Art par : Ben mais par mais par de comme de de de par par de cous de mais par de cous par de me cous par de le compe de vous de par : Et par de cous aut par cous par : Bon de par de vous par de se de pa \n",
      "\n",
      "Artrée Astire qui ce le de oune ce la se fair qui de c'aut pure vous an ! Astier de vous piert : Et par de il nome ce des ! Livre que de ret vous d'a pous par con alous que se condre de que que vous ilo \n",
      "\n",
      "Arquinier : Et sai vous le ane c'est je ses ça tai le fair l'en quoi (allemas comme der ce san, jes et couse fai fercpence ton veus de, Le ets alorther d'seur ! Noud enu que c'que ! A’aves des pat, pas  \n",
      "\n",
      "1.91514503002\n",
      "Epochs: 0\n",
      "Art : Ben de les de le les de se cous par de la par par comme de vous aus aut comme de vous alont de par de vous le le vous le tait de vous au de la par par de sa mais par de vous de vous par de comme d \n",
      "\n",
      "Arstier, Sire : est nor de ches de chesse de Con su Touc de au dandeur que de vostier, Léodagan : Mai la de un ens pas me cheux on ! Et tout m'vous est part, aut fais. Lives coun les le de vous commen d \n",
      "\n",
      "Arstier : Bertier sais. Artri ! Ben de San dit. vous jopais de dain on enssier. Ar : Percenre quand pas et : Boute sous, si il alo Sé Le mamest c’ent boique ton pan, la mois aloites chous procs baurivre \n",
      "\n",
      "1.8867252326\n",
      "Epochs: 0\n",
      "Arstier : Perce vous de la par de vous ave de vous alle que de vous par de vous avent de vous au de que c'est par de vous par cons par de vous par : Et par de vous par de sais la cous pas alle de le tou \n",
      "\n",
      "Arsille Alexa de vous aux et vous le uctestie que comme que de suins de les cont c'est mais ame de ai ent par par pait ent quis par pas par de la par d'ardis de c’est pas bon c'ent astiel vous si est j' \n",
      "\n",
      "Ars morfe trétent arontent par de dos, ents vre pous, ittien ce sies vous narsiènez j'estaure pars partiel ça de pous onle se anire aux c'est lars alle de vrus  nois de pest est ce vous les mon ! C'e qu \n",
      "\n",
      "1.86318146944\n",
      "Epochs: 0\n",
      "Art : Oui comme de vous le sa me de sa par de vous de vous aut se comme de vous le vous de vous de vous alle vous aut par de vous alle de vous avende de vous alle de vous par de vous par de vous par com \n",
      "\n",
      "Arti alle que d'vous pous amande se ceur par cevencon du oui en c'est la de que le vous mais gans bonné élest cons parde nous ente voules dé berdier que socse quandre Alexand aire vais des vous par de m \n",
      "\n",
      "Arxa l5 mait eni mait qu'dous l'ais de commonne de ples ous ves ces d’à fietand ait tais sentrai, ça iécest connoire cevous pout par à comme que ettronse ji'ais madère la fein res Fercevand : Arthur : Ç \n",
      "\n",
      "1.86353129625\n",
      "Epochs: 0\n",
      "Arstier de vous par de le comme de qui de vous par de vous sous au de vous pas par cont pas par de vous moit de vous de la de de cont fais comme de que mais de comme de vous par de vous de vous par de v \n",
      "\n",
      "Art Astier : Ces qui c'est un se par de as parte d'heme de vous me restier ? Arthur : Léodagan : Arthure : Le vous paas pas de vortomand en je ce cobon ! Non par des coute de que que qu'ent lat taus a m \n",
      "\n",
      "Arôdivre par de çai maintielot ? Son, Arthur : Mais se pous glar par le coute, I, La panle d'on ’anenaît lavre la ! Père combent don… Alor mes avie de la de de pas ! Jamne de pain ticour de commer ce su \n",
      "\n",
      "1.87142428398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "Art : Et par de vous au de par pas par par de la par par par de vous par par par de par par par par de cons au par par par tout pous par par pas pas parte que vous au par par par le par de cous par moit \n",
      "\n",
      "Arstier, La par : Séotre le mais pris par pas chor par de le se par bemen en par que cont en c'est la pas la trais sret que que le la par de le comme, Kaamelott, Livre Alot, : Ener cons la c'est prestie \n",
      "\n",
      "Arst ça natainue de vourde vour hec nour se tai je titais pperle se ce qui ! Bon l'euxa common mois, je partien remer de parçaine sou d'hien, Karadondanèper : Le ve housai vourez pas un vous par déhence \n",
      "\n",
      "1.78773679495\n",
      "Epochs: 0\n",
      "Arstier, Livre Astier, Livre Astier. Arthur : Mais par : Et par de la par de la par par de le sande de sous par de la mais de sande de par par par la mais par par la pas par de vous pas pas par de la pa \n",
      "\n",
      "Arckhe : Arthur : Et par ! En part éle pas comps le pas pa, la Bande par par le par que vous conter ça mon ? Livre ça me mais la tilostier, Léodagange par : Alexa danter par me combon au de ? Le mande l \n",
      "\n",
      "Arstie mame de jani vous ance que antres parte la binc quandiève quu ça topagtes le un de vous la par ! Man : Et pas lle vous au denti qui ce vous on pare de ca tars aus ? Karas : : Vous jere ! Je Kaana \n",
      "\n",
      "1.74590461016\n",
      "Epochs: 0\n",
      "Arstier, Livre II, Le vous ches cous de pas pas par de sais conte de les pas pas pas comme que vous au comme que le sais des les comme que vous aure de les par de vous pas pas pas par de les comme sance \n",
      "\n",
      "Arstier, La vous comme se ce la ce qui la pas pais dà vaus le et fais de ait que le sis mes duire les ses qui atant toutre : Le le vous puis ça ain que les cous pas sous d'mais par pas sivier. Parce rat \n",
      "\n",
      "Arr. Perocqui : Pers l'gaine danchener paces oui chompir hous paine tousse sa parolain pli tiert là de Bus d'un le la II, Kaais yu aloit par Alon, Jées Toëvez de vous pvien pous istiec ! Arthur : Se lau \n",
      "\n",
      "1.80512809038\n",
      "Epochs: 0\n",
      "Arstier, Le vous comme que vous de vous pas pas pas pas par de vous comme que vous moi le sa par pas les par de vous le tout de vous pas pour pas comme sous pas pas de fais par de vous le tout pas comme \n",
      "\n",
      "Arrchile : Ben d'hame faut sivre quand me tais fais, Kaaradond ! Pardièvre Astier : Percendandre Astier, Alexandre II, Jan en vous éntier ye que mois de vous là vous je unnelotre vous il toutes copaiurs \n",
      "\n",
      "Arstiez à vous d’huiver et par laus, ve que qu’ai du vous aure vous c'est nope va, percent se m'tampites :  maancent de che, c'est nog! Je Arthur :  l’ous pas trorte, brie vous partar il anor cone tout  \n",
      "\n",
      "1.81872014999\n",
      "Epochs: 0\n",
      "Arstier, Livre II, Le vous pas pas pas pas pas pas pas pas par de pas pas pas pous pas de pas par de le par le pas par de par de le vous par de pas de vous par de les par de de mais par de par de par de \n",
      "\n",
      "Arstier, la pu contes de ale que que vous pas avie none de un mais pas et par ! Arthur : Arthur : c’est cotrise se pale restie pas comppe de pour veis fioi par à de que li à vous pous vero Siard, La Din \n",
      "\n",
      "Ar8k Percerandrexancen : Nau vous ? Les toutaire alle, ête sanment que là ce bous de paut re, pistien on en ? Bon et de Gérandre qu’eux vélamalces de vous les nautai louver maivéoui dercest par pous en  \n",
      "\n",
      "1.73382262945\n",
      "Epochs: 0\n",
      "Art Alexandre Astier. Arthur : Oui en pas pas pas par de vous au de vous pas de pas au pas pas pas pas pas le pas pas pas le vous de le vous par par de sais de les par par de vous au de vous par pas par \n",
      "\n",
      "Arstier, Livre Astier. Prallaiste Guement berce savous on vien ! Arthur : Arthur : J'est moi, il souver pas j'alle on nons commen ? Alexandre Astier, Livre I, Léodagan : C’est Cour de vous ille pas le c \n",
      "\n",
      "ArBI Arthur : Astier, Lialez) alostie li jans pas les pregance comme d'Astirert, Kaalain : Et lais retille : Ça coin vous pes de parne ? La prodat, Livre son je a vous de soin remon ! Lééodaden. P’ravai \n",
      "\n",
      "1.69887562275\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Mais pas de vous pas de vous comme que ce vous de vous de que vous par de vous pas par de vous aut pas pas moi le vous le troi vous pas aut de chais de vous comme que cous pas par de v \n",
      "\n",
      "Arstier. Arthur : D'avie des de vous blesse toute par de chestre ce que comme d'de ce vous le teux passe con au comber, j'vous coppe de couger tout en pas pous vous ben le m'ai pour pas qua de que c'est \n",
      "\n",
      "Arque de que de… Arthur : Alexatd : Le Ouois pouander. Léodain que le puis que ? Perlécestièrexandre Astier ouit, vous pise de fun ! Frière et Aataunez Guir par : Silse pour vous devaus pas que porment  \n",
      "\n",
      "1.70181990147\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Mais pas de sans pas pas en pas pas pas comment pas pas pas pas pas le vous par comme que vous pas pas pas pas pas en pas pas par cons de vous pas pas comme que le vous le vous de les  \n",
      "\n",
      "ArM aplez : Le vous cous par passe ? Perce que fais dion mà tais me pas moi, vous allez me la de on de comple et mais de sis par d'garce que la mais les vous de gordes ! Le j'a que vous se tats, moin en \n",
      "\n",
      "Arzô vous de le cevais vus que Sercest Alexanderce. Alexandre Astier, Ducer,, l’alle, Quu elot ? Vous chier de Sionn, Livre II, Artal, Jeh aut robites ble sol su les comme, nouc ent par le cevait que ou \n",
      "\n",
      "1.68600728512\n",
      "Epochs: 0\n",
      "Arstier, Léodagan : Mais pas de pas pas les les les ce que le vous les les par de les par de les comment pas par par ce que le troi le tout les par les pas par les cous pour de que cous les de mais de l \n",
      "\n",
      "Arstier, Livre I, Le vous aveis la tous sour mais ais la couris là pais de renvalez foucer de lui les faite de cous pas s'ente pas en mais bien les par sien, mais copais de par est pas cute, ane mais le \n",
      "\n",
      "Art-À Le j'avez ? Élire la par darcouh léess hamenten coule que … de, là c'est-de de li la de cheédadoge Siè Perlerthur, Coume vous ences rerces moi, pas la c'est au tres tour en nourche, elous anc ? (' \n",
      "\n",
      "1.75105670691\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Ah arain : De pas pas pas au pas de sais pas de moin de les pas pas se les comme que j'ai la pas pas pas pas de mais sonte de vous le sais pas le vous de vous pas les comme de vous au  \n",
      "\n",
      "Arlà « Kaamelott, Léodagan : Ton sas pales quui et les pas les le pister la noss de lesse ait comment de mercent quand j'faire de faire qu'ous le de mont passe de ratene ende je un prorte à commen ? Léo \n",
      "\n",
      "ArrLivre Astier. U, Le Ben je ches, erte de… Arthur : Enre à qu’tien ! ELagand, la pané chorce que veng et botais : Et pas irie de ait vous lire su aripr. Lives là de qu'end quelodaz, Léotape dans la d' \n",
      "\n",
      "1.71707703829\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Non pas par le de pas pas de mais de vous compe de vous pas pas pas comme que vous de moi pas les pas pas les de mais des pas pas pas pas pas les pas pas pas par le pas pas pas pas pas \n",
      "\n",
      "Arstier. Léodis à fesssien ! Je mon pas par de mois pas vous le sais deme constier ! aa ? Perceval : Chien. Sion : Sien d'tonne de le me de seu de vous mois dressaber contre son j'au de la mois vous des \n",
      "\n",
      "ArAstier : Voos cous… Kaamendion, Livre se doc qu'elle que divre I, (Ka ail aviec Sion, C’it sion fous pas aus buméré. Il en je vous comme guèberaitle en on, c’est chassille énont, le coyucue, bieval ma \n",
      "\n",
      "1.66635116816\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Ah par : Et mais par de vous de mais par de vous alle de pas pas par les pas le trout par de mais pas pas pas pas pas pas pas pas par par mais pas pas pas pas pas par par de mais par m \n",
      "\n",
      "Arviert : Mais mais dit qu'est vous un pue ai fois, ce pas ben ce tromi, Kaamelle dit là sans le ditre de mas parter sui sui le que vous par plesser pas pas commer forte, Karadarcellez : Ben par aut de  \n",
      "\n",
      "Arqui : Tan équitaine vous de que va pas ? Alexandre Astier. Percexandre Astier, Pivre hiit par Alexandre ? Arthur : Et ceu que, veux hour nous porpis ? Arthuile : Ben m'ardire que pour pas boprais de d \n",
      "\n",
      "1.61972589254\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Ben ce vous les comme de vous pas pas pas pas par de vous les de vous au de vous pas pas le vous de cous de vous pas de vous avez de vous de pas pas pas pas pas mais pas comme de vous  \n",
      "\n",
      "ArLivre Astier. Arthur : Sien. Arthur : Oui de vous en vous cous pas bon, vous par en pis pris ? Land : En c'est vaus en les de me la pas mais ça Yvoi, Kaamelott, Léodagan : Me challis fait pars ce que  \n",
      "\n",
      "Arhle Astien, nobon et vouvopral : Mais nous enons. Arthur : J'est pettais pur chasé pas ! C'est ronte que çans leur pas allez là vous de les souc paut suit me vous écrit compe ! C’est êtais lais et vou \n",
      "\n",
      "1.65329035759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0\n",
      "Arstier. Arthur : Mais pas pas pas de mais pas pas pas les de pas avez de vous de mais pas comme que c'est pas pas pas pas pas pas pas pas pas pas pas de vous pas pas de mais comme conte de vous de mais \n",
      "\n",
      "Arstier. Aet : C'est vous vous ce gessen de mais aures la mais de augan de vous un ce vous la comme faise ce que fait comppos tout les prois de me avait de pas moi : Perces de pas ça les doches la toute \n",
      "\n",
      "Arque Il vont parte d'Alexandre Antier. J'est Séhi : Je de pestens yue qu’et ent pour en je vous pris dans chotent ce vous rerces que pas ? Léodagan : Mais c'est pigte séce, ven teu tout que Bout, et ça \n",
      "\n",
      "1.6422224021\n",
      "Epochs: 0\n",
      "Ars et comme que le trous pas par pas pas avez de les pas pas pas les pas pas les ce vous pas pas comple sous pas pas de pas de pas pas pas de mais pas pas pas pas pas pas pas les pas pas pas les pas co \n",
      "\n",
      "Arqu’est ! Perceval : Nan, et le ceve coper coule ! Les cous vous de villes palenter de tout l’ier mandier, c'est pas complin de les c'est par l’aut parce aus comme ! C’est prandre Alexandre Astier. Kar \n",
      "\n",
      "Arstier. Arthur : Me, ffivul He pampors de vous allez, c'est vous aas sourde, es je plus pous vous sontier le foris, du pour boudte, la coge quand mais la petie re tites est de pour pus les qui j'ane d' \n",
      "\n",
      "1.67176899433\n",
      "Epochs: 0\n",
      "Arstier, Livre II, Le Duc que vous les comme que comme que c'est pas sous pas comme que vous pas pas mais par pas pas de pas par de cous parte que c'est pas de mais de les partien de vous pas pas pas co \n",
      "\n",
      "Arqui : Perceval : Sirie de cont son en moi même de vous de vous alle de cous que que la nous pas pas des faire comme, les ? Arthur : Oui, ça parte que lait que j'aver tout vous bon le sol pas je vous c \n",
      "\n",
      "Arh Chartient, Kaamelott, Kavarorain : Et  siuser Framête ? Arthur : Vous sui de faiste, bien et dui prre pour bien on ! D'ests, mais ? Le pas de boire à qu'en pomis ? Guenot : Mes de pou pas pisiter y  \n",
      "\n",
      "1.64050317764\n",
      "Epochs: 0\n",
      "Ars ! Arthur : Mais de vous alle se vous pas pas pas comme de vous de sais pas le pas pas le comme de vous pas pas comme de vous pas se pas pas comme que vous pas par mais pas pas pas de vous de vous au \n",
      "\n",
      "Arqui : Et à faitre de vous que c'est comper conter pas ce la me comment les ça de d'ain, duais mais parte sur fous a diverse la pas retair le suis ça mais sur en-chame de mais ? Arthur : Mais pous de v \n",
      "\n",
      "Arque de sans parte, je pous vare Di en ditre da fait de pas faise, astiot, j'vous à pence qu’il dans et troit. Percevan (lui au ce vous j'toin ert heme sire se compais de pauntens boussen, là pas dans  \n",
      "\n",
      "1.63275519848\n",
      "Epochs: 0\n",
      "Arstier, Livre II, Léodagan : Ah par Alexandre Astier, Livre II, Le Duc est pas pas pas pas pas les les pas pas pas pas pas pas pas pas pas pas pas pas pas pas pas pas pas pas pas pas se pris pas pas co \n",
      "\n",
      "Ar. Artuant, Kaamelott, Léodagan : Que votte au foit rande quoi la toutes le que comme sin prectes des conter pas plue de vous arter de vier se chastier, sa pous pour pas leur en pour partien, en sive p \n",
      "\n",
      "Arstierèt legatte un riner colise que moi ce pour des joue ça mais pas lessériesait pas le oucs, ben, mais en si vous faut pas m'alles les aller c'est consaliet d'vous ! Land au pertu de le l'in rcous s \n",
      "\n",
      "1.59177736282\n",
      "Epochs: 0\n",
      "Arstier. Perceval : Et partier de vous le sais de mais comme de mais de mais de pas par de mais pas comme de vous pas par pas de pas de mais pas parte que la par de vous alle de pas pas par de mais par  \n",
      "\n",
      "Art : C’est soumelott, Livre III, Le Duc est on mon de comme demant le sur aller pas, la prise de vous aucher dire de manchez de les toutentier : Ça pas est méles d'Aquitaine : Oui avez la trentre, c’es \n",
      "\n",
      "Arstier, Livre I, Je aroi tient suit ? Kar! Alexandre Astier, c'est que commer tourtant ! Perceval : Et céquillend : D'on sues. Karand : Fortes ? Alexandre Astier, Kaamelliert ? Arthur : Qu'éexandre Ant \n",
      "\n",
      "1.59627177\n",
      "Epochs: 0\n",
      "Arstier. Arthur : Mais pas pas sous pas de le compre de conte de vous de pas pas par de vous de vous pas pas par de vous de moi ? Arthur : Ah alors, c'est pas pas pas pas les compre de vous avez de vous \n",
      "\n",
      "Ars il et des faire mais les de vous alles de le conte, le pas ene d'Astier, Livre I Palcest le mêtes de leus vous ? Guine en d'rience pas pas pas ! Arthur : Et mi et bon par hemaine attente pout tout d \n",
      "\n",
      "Arstier. Arthur : Mais de ples oi faini tout. Lodagan : Mais de sait gaus, Léodagan ettien : Roan : Dine, c'est prais jourge des un les le vous alle prestres ce vais à tauge ? Alexandre Astier. Arthur : \n",
      "\n",
      "1.60786815882\n",
      "Epochs: 0\n",
      "Arstier, Livre II, Léodagan : Non au les pas pas parte pas la pas de mais comme que j'ais parce que je sais pas pas par le trous pas pas pas pas les pas pas en pas pas de mais pas pas pas partier de mai \n",
      "\n",
      "Arlaapagant : Ben on vous la parce que sa par, là vous mêment sous le tous sui et couriet tout je partente le parsi, les ? Perceval : Alexandre Astier. Perceval : Tamelott, Livre II, Le Duc des serte qu \n",
      "\n",
      "ArNÀxx(MBLOUÀQ5ë.Rk5xx Kaamelot janorses la un peux c’est Pouvreran, Kaamelott, Livre II, Le pas jàaux, Kaamelott, Kaabot. Perceval Et on et du ce qu’il ses pour par de pojest ? Arthur : Vous éndame me  \n",
      "\n",
      "1.5739609766\n",
      "Epochs: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-777826c99ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-227-0320ee966e23>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(prime_str, predict_len, temperature)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Sample from the network as a multinomial distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-225-ed97f0ba55cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         )\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, beta, alpha, inplace)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         return torch.addmm(beta, add_matrix, alpha,\n\u001b[0;32m---> 31\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "update_loss_every = 50\n",
    "print_every = 50\n",
    "\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "lr = 0.001\n",
    "lr_min = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "list_random = list(np.random.randint(0, len(data_vectors), n_epochs))\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    for i, elem in enumerate(data_vectors):\n",
    "        x = elem[\"x\"]\n",
    "        y = elem[\"y\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hidden = rnn.init_hidden(1)\n",
    "        output, hidden = rnn(x.view(1, -1), hidden)\n",
    "        #y_tensor = int_to_one_hot_vectors(y.data.tolist(), n_characters)\n",
    "        y_tensor = y\n",
    "        loss = criterion(output.squeeze(0), y_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        all_losses.append(loss.data[0])\n",
    "        if i % print_every == 0:\n",
    "            print('Epochs: {}'.format(epoch))\n",
    "            print(generate('Ar', 200, 0.2), '\\n')\n",
    "            print(generate('Ar', 200, 0.6), '\\n')\n",
    "            print(generate('Ar', 200, 0.8), '\\n')\n",
    "            print(np.mean(all_losses[-print_every:]))\n",
    "        \n",
    "        \"\"\"\n",
    "        if i % update_loss_every == 0:\n",
    "            print(\"Update Loss !\")\n",
    "            print(all_losses[-4:])\n",
    "            if is_update_lr(all_losses):\n",
    "                lr = max(lr_min, lr / 5)\n",
    "                print(\"New Lerning Rate: {}\".format(lr))\n",
    "                optimizer = torch.optim.SGD(rnn.parameters(), lr=lr)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_update_lr(last_losses):\n",
    "    if len(last_losses) < 5:\n",
    "        return False\n",
    "    \n",
    "    if last_losses[-2] - last_losses[-1] > (last_losses[-1] / 100) and and):\n",
    "        print(\"Update LOSS !!!!\")\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd5073c860>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd59e3eb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True)\n",
    "target = Variable(torch.randn(3, 5))\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
